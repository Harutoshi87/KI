* 인공지능학습(dl/ml) : 
     - 지도학습 : 회귀분석 / logistic regression(이진분류) / 다중분류 => DNN
     - 비지도학습 : 군집화
     - 강화학습
* DNN, RNN, LSTM, 자연어처리
* 스케일 조정(정규화, 표준화)하는 목적? 모델 계산의 안정성 향상
 
* model = Sequential([]) : 순차적 레이어 모델 생성
  model = Model(inputs=xx, outputs=xx) 병렬모델(함수형 API)
     이중분류의 출력층 Dense(1, activation='sigmoid')
     다중분류의 출력층 Dense(3, activation='softmax')
* 학습과정 설정 : compile()
     - 손실함수(categorical_crossentropy,
            sparse_categorical_crossentropy),
     - optimizer(adam),
     - 평가지표(metrics) : accuracy, precision, recall
	accuracy(정확도) = (TN+TP)/(TN+FP+FN+TP)
	precision(정밀도) = TP / 예측을 1이라고 한 수(FP+TP) -> 예측한 Positive 중 실제 Positive 비율 (예측값기준)
	recall(재현율=민감도) = TP / 실제값이 1인 수(FN+TP) -> 실제 Positive 중에서 모델이 맞게 예측한 비율 (실제값기준)
	F1 score = recall과 precision의 조화평균
	 * F1 score =2* (precision*recall)/(precision+recall)
	 * F1 score는 평가 단계에서 활용

trade-off 관계
Precision을 높이려면 -> 1일 확률이 높은 것만 Positive로 예측함 -> recall이 낮아질 수 있음
recall을 높이려면 -> 조금이라도 가능성이 있으면 Positive로 예측-> precision이 낮아질 수 있음

     - accuracy 높이기 위한 방법들
	데이터 확보, 모델 수정(레이어 추가, units 수 증가), epoch 조정, optimizer 변경

     - 과적합 방지를 위한 방법
	dropout, 과적합 방지 (validation data &/ train data 추가, 균형 잡히지 않은 data 증강, 활성화 함수 relu 계열, tanh)

     - 모델 저장(확장자 : h5, keras)
	model.save('파일명') / load_model('파일명')

* 자연어처리 : nltk(영어), konlpy(한국어)/mecab(한국어/일본어) 
	      morphs() : 형태소 분석(추출), nouns() : 명사 분석(추출), pos() : 품사 분석(tagging)  => [(형태소, 품사), ('강', 'NNP'), ...] : tuple list
	      nltk(영어), konlpy(한국어)/mecab(한국어/일본어)

* RNN(LSTM/GRU, Seq2Seq) : 텍스트 분류(해석), 자연어 텍스트 생성, 시계열 데이터 예측, 작곡

* CNN : 이미지 분류




